name: benchmark comment

on:
  workflow_run:
    workflows: ["benchmarks"]
    types:
      - completed

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  comment:
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success'

    steps:
      - name: Download benchmark results
        id: download
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          name: benchmark-results
          path: benchmark-results/

      - name: Check if this is a PR with benchmark results
        id: check
        run: |
          # Check if artifacts were downloaded successfully
          if [ "${{ steps.download.outcome }}" != "success" ]; then
            echo "is_pr=false" >> $GITHUB_OUTPUT
            echo "ðŸ“‹ No benchmark artifacts found"
            exit 0
          fi

          # Check for PR metadata
          if [ -f "benchmark-results/pr_number.txt" ]; then
            echo "is_pr=true" >> $GITHUB_OUTPUT
            echo "pr_number=$(cat benchmark-results/pr_number.txt)" >> $GITHUB_OUTPUT
            echo "âœ… Found PR metadata for PR #$(cat benchmark-results/pr_number.txt)"
          else
            echo "is_pr=false" >> $GITHUB_OUTPUT
            echo "ðŸ“‹ No PR metadata found - this was likely a main branch run"
          fi

      - name: Comment PR with results
        if: steps.check.outputs.is_pr == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read benchmark results
            const results = JSON.parse(fs.readFileSync('benchmark-results/bench-results.json', 'utf8'));

            // Check if comparison data exists
            const comparisonPath = 'benchmark-results/bench-results-comparison.json';
            let comparison = null;
            if (fs.existsSync(comparisonPath)) {
              comparison = JSON.parse(fs.readFileSync(comparisonPath, 'utf8'));
            }

            let comment = '## ðŸ“Š Benchmark Results\n\n';

            if (comparison && comparison.comparisons) {
              // Enhanced table with baseline comparison
              comment += '| Benchmark | Current | Baseline | Change |\n';
              comment += '|-----------|---------|----------|--------|\n';

              for (const c of comparison.comparisons) {
                const status_icon = {
                  'regression': 'ðŸ”´',
                  'slower': 'ðŸŸ¡',
                  'faster': 'ðŸŸ¢',
                  'neutral': 'âšª',
                  'new': 'ðŸ†•'
                }[c.status] || 'âšª';

                let changeStr = '';
                if (c.status === 'new') {
                  changeStr = `${status_icon} *new*`;
                } else if (c.change_pct !== null) {
                  const sign = c.change_pct > 0 ? '+' : '';
                  changeStr = `${status_icon} ${sign}${c.change_pct.toFixed(1)}%`;
                }

                const currentTime = c.current.median_display;
                const baselineTime = c.baseline ? c.baseline.median_display : '-';

                comment += `| ${c.name} | ${currentTime} | ${baselineTime} | ${changeStr} |\n`;
              }

              // Summary
              const regressions = comparison.comparisons.filter(c => c.status === 'regression');
              const improvements = comparison.comparisons.filter(c => c.status === 'faster');

              comment += '\n';
              if (regressions.length > 0) {
                comment += `âš ï¸ **${regressions.length} regression(s)** detected\n`;
              }
              if (improvements.length > 0) {
                comment += `âœ¨ **${improvements.length} improvement(s)** detected\n`;
              }
              if (regressions.length === 0 && improvements.length === 0) {
                comment += 'âœ… Performance is stable\n';
              }

            } else {
              // Fallback: simple table without comparison
              comment += '| Benchmark | Median | Min |\n';
              comment += '|-----------|--------|-----|\n';

              for (const [name, data] of Object.entries(results.benchmarks)) {
                comment += `| ${name} | ${data.median_display} | ${data.min_display} |\n`;
              }

              comment += '\n> ðŸ“‹ No baseline available for comparison\n';
            }

            comment += '\n<sub>ðŸ¤– Generated by godot-bevy CI</sub>';

            const prNumber = ${{ steps.check.outputs.pr_number }};

            // Find existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('ðŸ“Š Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment,
              });
              console.log('Updated existing benchmark comment');
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: comment,
              });
              console.log('Created new benchmark comment');
            }
