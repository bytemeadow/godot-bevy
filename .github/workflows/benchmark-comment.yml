name: benchmark comment

on:
  workflow_run:
    workflows: ["benchmarks"]
    types: [completed]

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  comment:
    name: Post benchmark results
    runs-on: ubuntu-latest
    # Only run for PRs and when benchmarks succeeded
    if: |
      github.event.workflow_run.conclusion == 'success' &&
      github.event.workflow_run.event == 'pull_request'

    steps:
      - name: Download benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          name: benchmark-results

      - name: Read PR number
        id: pr
        run: |
          # Artifacts maintain their upload path structure (itest/ prefix)
          if [ -f itest/pr_number.txt ]; then
            echo "number=$(cat itest/pr_number.txt)" >> $GITHUB_OUTPUT
          elif [ -f pr_number.txt ]; then
            echo "number=$(cat pr_number.txt)" >> $GITHUB_OUTPUT
          else
            echo "Error: PR number not found"
            exit 1
          fi

      - name: Post comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read comparison data (check both possible locations)
            let comparisonPath = 'itest/comparison.json';
            if (!fs.existsSync(comparisonPath)) {
              comparisonPath = 'comparison.json';
            }
            const comparison = JSON.parse(fs.readFileSync(comparisonPath, 'utf8'));

            // Build comment
            let comment = '## üìä Benchmark Results\n\n';

            // Summary section
            const { regressions, improvements, new: newBenchmarks, total } = comparison.summary;

            if (regressions > 0) {
              comment += `> ‚ö†Ô∏è **${regressions} performance regression(s) detected**\n\n`;
            } else if (improvements > 0) {
              comment += `> ‚ú® **${improvements} performance improvement(s) detected**\n\n`;
            } else if (newBenchmarks === total) {
              comment += `> üÜï **First benchmark run** - ${total} benchmarks baselined\n\n`;
            } else {
              comment += `> ‚úÖ **Performance is stable** - no significant changes\n\n`;
            }

            // Results table
            comment += '| Benchmark | Current | Baseline | Change |\n';
            comment += '|-----------|---------|----------|--------|\n';

            for (const bench of comparison.benchmarks) {
              let changeStr = '';

              if (bench.status === 'new') {
                changeStr = 'üÜï *new*';
              } else if (bench.change_pct !== null) {
                let icon = '‚ö™';
                if (bench.status === 'regression') icon = 'üî¥';
                else if (bench.status === 'slower') icon = 'üü°';
                else if (bench.status === 'faster') icon = 'üü¢';

                const sign = bench.change_pct > 0 ? '+' : '';
                changeStr = `${icon} ${sign}${bench.change_pct.toFixed(1)}%`;
              }

              const baseline = bench.baseline || '*-*';
              comment += `| \`${bench.name}\` | ${bench.current} | ${baseline} | ${changeStr} |\n`;
            }

            // Details section
            comment += '\n<details>\n<summary>‚ÑπÔ∏è About these benchmarks</summary>\n\n';
            comment += '- **Regression threshold:** Performance drops >10% are marked as regressions\n';
            comment += '- **Caution threshold:** Performance drops >5% are marked with caution\n';
            comment += '- **Improvement threshold:** Performance gains >5% are marked as improvements\n';
            comment += '- **Runner:** Ubuntu (GitHub Actions)\n';
            comment += '- **Baseline:** Latest benchmarks from `main` branch\n';
            comment += '</details>\n\n';
            comment += '<sub>ü§ñ Generated by godot-bevy CI</sub>';

            // Get PR number
            const prNumber = ${{ steps.pr.outputs.number }};

            // Find existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('üìä Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment,
              });
              console.log('‚úÖ Updated existing benchmark comment');
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: comment,
              });
              console.log('‚úÖ Created new benchmark comment');
            }