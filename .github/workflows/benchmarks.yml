name: benchmarks

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main]

env:
  CARGO_TERM_COLOR: always
  GODOT_VERSION: "4.5.1"

permissions:
  contents: write  # Need write to push to gh-benchmarks branch

jobs:
  run-benchmarks:
    name: Run benchmarks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: . -> target

      - name: Install Linux dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libasound2-dev libudev-dev pkg-config

      - name: Setup Godot
        uses: chickensoft-games/setup-godot@v2
        with:
          version: ${{ env.GODOT_VERSION }}
          use-dotnet: false
          include-templates: false

      - name: Build itest in release mode
        working-directory: itest/rust
        run: cargo build --release

      - name: Copy library to Godot project
        working-directory: itest
        run: |
          mkdir -p godot/lib
          cp rust/target/release/libgodot_bevy_itest.so godot/lib/ 2>/dev/null || \
          cp rust/target/release/godot_bevy_itest.dll godot/lib/ 2>/dev/null || \
          cp rust/target/release/libgodot_bevy_itest.dylib godot/lib/ 2>/dev/null || true

          # Update .gdextension paths
          sed -i 's|res://../../target/debug/|res://lib/|g' godot/itest.gdextension
          sed -i 's|res://../../target/release/|res://lib/|g' godot/itest.gdextension

      - name: Import Godot project
        working-directory: itest
        run: godot --headless --path godot --import --quit || true

      - name: Run benchmarks and extract JSON
        working-directory: itest
        run: |
          # Run benchmarks with JSON output enabled
          export BENCHMARK_JSON=1
          export BENCHMARK_JSON_PATH=bench-results.json

          godot --headless --path godot BenchRunner.tscn --quit-after 60000 2>&1 | tee bench-output.txt

          # Extract JSON from output as fallback if file write failed
          if [ ! -f bench-results.json ]; then
            sed -n '/===BENCHMARK_JSON_START===/,/===BENCHMARK_JSON_END===/p' bench-output.txt | \
              sed '1d;$d' > bench-results.json
          fi

          # Verify we have valid JSON
          if ! jq empty bench-results.json 2>/dev/null; then
            echo "Error: Invalid JSON output"
            exit 1
          fi

          echo "âœ… Benchmarks complete"

      - name: Fetch baseline (PR only)
        if: github.event_name == 'pull_request'
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd itest
          # Try to fetch baseline from gh-benchmarks branch
          curl -sf https://raw.githubusercontent.com/${{ github.repository }}/gh-benchmarks/baseline.json \
            > baseline.json 2>/dev/null || echo '{"benchmarks":{}}' > baseline.json

      - name: Generate comparison report
        if: github.event_name == 'pull_request'
        working-directory: itest
        run: |
          # Create Python script for comparison
          cat > compare.py << 'EOF'
          import json
          import sys

          with open('bench-results.json') as f:
              current = json.load(f)

          try:
              with open('baseline.json') as f:
                  baseline = json.load(f)
          except:
              baseline = {"benchmarks": {}}

          comparison = {
              "benchmarks": [],
              "summary": {"total": 0, "regressions": 0, "improvements": 0, "new": 0}
          }

          for name, curr_data in current.get("benchmarks", {}).items():
              base_data = baseline.get("benchmarks", {}).get(name)

              entry = {
                  "name": name,
                  "current": curr_data.get("median_display", "N/A"),
                  "baseline": None,
                  "change_pct": None,
                  "status": "new"
              }

              if base_data:
                  entry["baseline"] = base_data.get("median_display", "N/A")

                  try:
                      current_ns = float(curr_data.get("median_ns", 0))
                      baseline_ns = float(base_data.get("median_ns", 0))

                      if baseline_ns > 0:
                          change_pct = ((current_ns - baseline_ns) / baseline_ns) * 100
                          entry["change_pct"] = change_pct

                          if change_pct > 10:
                              entry["status"] = "regression"
                              comparison["summary"]["regressions"] += 1
                          elif change_pct > 5:
                              entry["status"] = "slower"
                          elif change_pct < -5:
                              entry["status"] = "faster"
                              comparison["summary"]["improvements"] += 1
                          else:
                              entry["status"] = "neutral"
                  except:
                      pass
              else:
                  comparison["summary"]["new"] += 1

              comparison["benchmarks"].append(entry)

          comparison["summary"]["total"] = len(comparison["benchmarks"])

          with open('comparison.json', 'w') as f:
              json.dump(comparison, f, indent=2)

          # Exit with error if regressions detected
          sys.exit(1 if comparison["summary"]["regressions"] > 0 else 0)
          EOF

          python3 compare.py || REGRESSION_DETECTED=$?

          # Save PR context
          echo "${{ github.event.pull_request.number }}" > pr_number.txt
          echo "${{ github.event.pull_request.head.sha }}" > pr_sha.txt

      - name: Upload benchmark artifacts
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            itest/bench-results.json
            itest/baseline.json
            itest/comparison.json
            itest/pr_number.txt
            itest/pr_sha.txt

      - name: Update baseline (main branch)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Configure git
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          # Save the benchmark results before switching branches
          cp itest/bench-results.json /tmp/baseline.json

          # Stash any local changes before switching branches
          # This includes the modified .gdextension file
          git stash push -m "Temporary stash for benchmark workflow" || true

          # Fetch or create gh-benchmarks branch
          git fetch origin gh-benchmarks 2>/dev/null || true

          if git show-ref --verify --quiet refs/remotes/origin/gh-benchmarks; then
            git checkout gh-benchmarks
            git pull origin gh-benchmarks
          else
            git checkout --orphan gh-benchmarks
            git rm -rf . 2>/dev/null || true
            echo "# Benchmark Baselines" > README.md
            git add README.md
            git commit -m "Initialize benchmarks branch"
          fi

          # Copy and commit new baseline
          cp /tmp/baseline.json baseline.json
          git add baseline.json
          git commit -m "Update baseline from ${{ github.sha }}" || echo "No changes"
          git push origin gh-benchmarks